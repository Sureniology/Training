{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf3GloRNvOOG"
   },
   "source": [
    "# **Practice Project: Amazon Product Reviews**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________\n",
    "\n",
    "Welcome to the Practice Project on Recommendation Systems. We will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model. \n",
    "\n",
    "--------------\n",
    "## **Context**\n",
    "--------------\n",
    "\n",
    "E-commerce websites like Amazon, Flipkart uses different recommendation models to provide personalized suggestions to different users. For example, one of the recommendation models that Amazon uses is item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n",
    "\n",
    "----------------\n",
    "## **Objective**\n",
    "----------------\n",
    "\n",
    "Build a recommendation system to recommend products to customers based on their previous ratings for other products.\n",
    "\n",
    "-----------------------------\n",
    "## **Dataset** \n",
    "-----------------------------\n",
    "\n",
    "The Amazon dataset contains the following attributes:\n",
    "\n",
    "- **userId:** Every user identified with a unique id\n",
    "- **productId:** Every product identified with a unique id\n",
    "- **Rating:** The rating of the corresponding product by the corresponding user\n",
    "- **timestamp:** Time of the rating. We **will not use this column** to solve the current problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYrMMOH6sm8f"
   },
   "outputs": [],
   "source": [
    "# uncomment if you are using google colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hczXgBkvOOG"
   },
   "source": [
    "### Importing Libraries\n",
    "#### One of the first steps in any data science task is importing the necessary tools you will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIANuJXXm2wt"
   },
   "outputs": [],
   "source": [
    "# Installing surprise library, only do it for first time\n",
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gem2ozi_vOOG"
   },
   "outputs": [],
   "source": [
    "# Used to ignore the warning given as output of the code\n",
    "import warnings                                 \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Basic libraries of python for numeric and dataframe computations\n",
    "import numpy as np                              \n",
    "import pandas as pd\n",
    "\n",
    "# Basic library for data visualization\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "# Slightly advanced library for data visualization            \n",
    "import seaborn as sns                           \n",
    "\n",
    "# A dictionary output that does not raise a key error\n",
    "from collections import defaultdict             \n",
    "\n",
    "# A performance metrics in surprise\n",
    "from surprise import accuracy\n",
    "\n",
    "# Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# Class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# For model tuning model hyper-parameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# For splitting the rating data in train and test dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# For implementing similarity based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# For implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# For implementing cross validation\n",
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewHMWerQ2N9T"
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdQIx3OLvOOG"
   },
   "outputs": [],
   "source": [
    "# Col_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "rating = pd.read_csv('ratings_Electronics.csv', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "rating = rating.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAW3gTmB2N9a"
   },
   "source": [
    "Let's check the **info** of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zF1K1hDvOOG"
   },
   "outputs": [],
   "source": [
    "rating.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "202Ux9MH2N9f"
   },
   "source": [
    "- There are **7824481 observations** and **4 columns** in the data\n",
    "- The data type of the timestamp column is int64 which is not correct. We can convert this to DateTime format but **we don't need timestamp for our analysis**. Hence, **we can drop this column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fltadjTcvOOH"
   },
   "outputs": [],
   "source": [
    "#Dropping timestamp column\n",
    "#rating = rating.drop(['timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsXibw2_6Z1S"
   },
   "source": [
    "### **Exploring the dataset**\n",
    "\n",
    "#### Q 1.1 Print the top 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q6gs-IO2N9i"
   },
   "outputs": [],
   "source": [
    "# Printing the top 5 rows of the dataset Hint use .head()\n",
    "# Remove _______- and complete the code\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIYnXf076Z1T"
   },
   "source": [
    "#### Q 1.2 Describe the distribution of ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNJzJWjj6Z1T"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "\n",
    "# Remove ____________ and complete the code\n",
    "sns.countplot(_______________)\n",
    "\n",
    "plt.tick_params(labelsize = 10)\n",
    "plt.title(\"Distribution of Ratings \", fontsize = 10)\n",
    "plt.xlabel(\"Ratings\", fontsize = 10)\n",
    "plt.ylabel(\"Number of Ratings\", fontsize = 10)\n",
    "plt.ticklabel_format(useOffset=False, style='plain', axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPq3tw086Z1U"
   },
   "source": [
    "**Write your Answer here:_______**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HI8kZV0bm2wv"
   },
   "outputs": [],
   "source": [
    "df=rating.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGrub1kTm2ww"
   },
   "source": [
    "**As this dataset is very large and has 7824482 observations, it is not computationally possible to build a model using this.Moreover, there are many users who have only rated a few products and also there are products which are rated by very less users. Hence we can reduce the dataset by considering certain Logical assumption.**\n",
    "\n",
    "Here, We will be taking users who have given at least 50 rating, and the products who has at least 5 rating, as when we shop online we prefer to have some number of rating of a product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DW-Ju69NhFXy"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the users\n",
    "users = rating.user_id\n",
    "# Create a dictionary from users to their number of ratings\n",
    "ratings_count = dict()\n",
    "for user in users:\n",
    "    # If we already have the user, just add 1 to their rating count\n",
    "    if user in ratings_count:\n",
    "        ratings_count[user] += 1\n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[user] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWhzrLu-hFXy"
   },
   "outputs": [],
   "source": [
    "# We want our users to have at least 50 ratings to be considred\n",
    "RATINGS_CUTOFF = 50\n",
    "remove_users = []\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "rating = rating.loc[~rating.user_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XktiDwuz6Z1U"
   },
   "outputs": [],
   "source": [
    "rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEC_csQvm2ww"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the users\n",
    "items = rating.item_id\n",
    "# Create a dictionary from users to their number of ratings\n",
    "ratings_count = dict()\n",
    "for item in items:\n",
    "    # If we already have the user, just add 1 to their rating count\n",
    "    if item in ratings_count:\n",
    "        ratings_count[item] += 1\n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[item] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKB9PmGhm2ww"
   },
   "outputs": [],
   "source": [
    "# We want our item to have at least 5 ratings to be considred\n",
    "RATINGS_CUTOFF = 5\n",
    "remove_items = []\n",
    "for item, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_items.append(item)\n",
    "rating = rating.loc[~rating.item_id.isin(remove_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uu5G1hmgm2ww"
   },
   "outputs": [],
   "source": [
    "rating.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOBD03d9vOOH"
   },
   "source": [
    "#### Q 1.3 What is the total number of unique users and unique items? (1 Mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMpbsZGGvOOH"
   },
   "outputs": [],
   "source": [
    "#Finding number of unique users\n",
    "#remove _______- and complete the code\n",
    "\n",
    "rating['user_id']._____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI8gofnx2N9m"
   },
   "source": [
    "**Write your Answer here:**\n",
    "\n",
    "- There are **1540 users** in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9A6Qmo_6vOOH"
   },
   "outputs": [],
   "source": [
    "#Finding number of unique items\n",
    "#remove _______- and complete the code\n",
    "rating['item_id'].__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDWJghQ62N9o"
   },
   "source": [
    "**Write your Answer here:_____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mR9tzSzTvOOH"
   },
   "source": [
    "#### Q 1.4 Is there an item in which the same user interacted with it more than once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xstEDCVfvOOH"
   },
   "outputs": [],
   "source": [
    "rating.groupby(['user_id', 'item_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1E2i5rZvOOI"
   },
   "outputs": [],
   "source": [
    "rating.groupby(['user_id', 'item_id']).count()['rating'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynCEs7q3vOOI"
   },
   "source": [
    "**Write your Answer here:____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQgjqRnevOOI"
   },
   "source": [
    "#### Q 1.5 Which one is the most interacted item in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LBbXdoDvOOI"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "rating['item_id']._________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSo-c_XAvOOI"
   },
   "source": [
    "**Write your Answer here:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVkc1FK22N9r"
   },
   "outputs": [],
   "source": [
    "#Plotting distributions of ratings for 74 interactions with itemid B0088CJT4U\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "rating[rating['item_id'] == 'B0088CJT4U']['rating'].value_counts().plot(kind='bar')\n",
    "\n",
    "plt.xlabel('Rating')\n",
    "\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pQn17ro2N9s"
   },
   "source": [
    "**Write your Answer here:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kXJ_iTEvOOI"
   },
   "source": [
    "#### Q 1.6 Which user interacted the most with any item in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7ehlMLDvOOI"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "rating['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-Sdna2ovOOI"
   },
   "source": [
    "**Write your Answer here:___________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHReghdivOOI"
   },
   "source": [
    "#### Q 1.7 What is the distribution of the user-item interactions in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XArWJ7l2N9v"
   },
   "outputs": [],
   "source": [
    "#Finding user-item interactions distribution\n",
    "count_interactions = rating.groupby('user_id').count()['item_id']\n",
    "count_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoNCRm88vOOI"
   },
   "outputs": [],
   "source": [
    "#Plotting user-item interactions distribution\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "#remove _______- and complete the code\n",
    "sns.histplot(____________)\n",
    "\n",
    "plt.xlabel('Number of Interactions by Users')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmj5nPiN2N9w"
   },
   "source": [
    "**Write your Answer here:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQF80jaHhFX2"
   },
   "source": [
    "#### As we have now explored the data, let's start building Recommendation systems\n",
    "\n",
    "### **Question 2: Create Rank-Based Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqFN5jDJvOOJ"
   },
   "source": [
    "### Model 1: Rank Based Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W26vIRn1vOOJ"
   },
   "source": [
    "Rank-based recommendation systems provide recommendations based on the most popular items. This kind of recommendation system is useful when we have **cold start** problems. Cold start refers to the issue when we get a new user into the system and the machine is not able to recommend items to the new user, as the user did not have any historical interactions in the dataset. In those cases, we can use rank-based recommendation system to recommend items to the new user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3t4uyGlvOOK"
   },
   "source": [
    "To build the rank-based recommendation system, we take **average** of all the ratings provided to each item and then rank them based on their average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuMR3XFIvOOK"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "#Calculating average ratings\n",
    "average_rating = rating.groupby('item_id').___________\n",
    "\n",
    "#Calculating the count of ratings\n",
    "count_rating = rating.groupby('item_id')._____________\n",
    "\n",
    "#Making a dataframe with the count and average of ratings\n",
    "final_rating = pd.DataFrame({'avg_rating':average_rating, 'rating_count':count_rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6NLX6FIvOOK"
   },
   "outputs": [],
   "source": [
    "final_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pv31nHm_2N9y"
   },
   "source": [
    "Now, let's create a function to find the **top n items** for a recommendation based on the average ratings of items. We can also add a **threshold for a minimum number of interactions** for a item to be considered for recommendation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fy0SbxnevOOK"
   },
   "outputs": [],
   "source": [
    "def top_n_items(data, n, min_interaction=30):\n",
    "    \n",
    "    #Finding items with minimum number of interactions\n",
    "    recommendations = data[data['rating_count'] >= min_interaction]\n",
    "    \n",
    "    #Sorting values w.r.t average rating \n",
    "    recommendations = recommendations.sort_values(by='avg_rating', ascending=False)\n",
    "    \n",
    "    return recommendations.index[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fi9vhL4Z2N9y"
   },
   "source": [
    "We can **use this function with different n's and minimum interactions** to get items to recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkz4LlTpvOOK"
   },
   "source": [
    "#### Recommending top 5 items with 50 minimum interactions based on popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-JX_ES9vOOK"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "list(top_n_items(_____________))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4vrsunx2N91"
   },
   "source": [
    "#### Now that we have seen how to apply the Rank-Based Recommendation System, let's apply Collaborative Filtering Based Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJI5kiiGvOOK"
   },
   "source": [
    "### Model 2: Collaborative Filtering Based Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoSujZuuvOOK"
   },
   "source": [
    "In this type of recommendation system, `we do not need any information` about the users or items. We only need user item interaction data to build a collaborative recommendation system. For example - \n",
    "<ol>\n",
    "    <li><b>Ratings</b> provided by users. For example - ratings of books on goodread, movie ratings on imdb etc</li>\n",
    "    <li><b>Likes</b> of users on different facebook posts, likes on youtube videos</li>\n",
    "    <li><b>Use/buying</b> of a product by users. For example - buying different items on e-commerce sites</li>\n",
    "    <li><b>Reading</b> of articles by readers on various blogs</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_3GtPzuvOOK"
   },
   "source": [
    "#### Types of Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igZX3WbqvOOK"
   },
   "source": [
    "- Similarity/Neighborhood based\n",
    "- Model based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Uo_MYMnVNB"
   },
   "source": [
    "Below we are building similarity based recommendation system using `cosine` similarity and using KNN to find similar users which are nearest neighbor to the given user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_T9DOvVnVNB"
   },
   "source": [
    "We will be using a new library - `surprise` to build the remaining models, let's first import the necessary classes and functions from this library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hxjJMTwnVNB"
   },
   "source": [
    "Below we are loading the `rating` dataset, which is a pandas dataframe, into a different format called `surprise.dataset.DatasetAutoFolds` which is required by this library. To do this we will be using the classes `Reader` and `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyh0lKmb6Z1a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df=rating[['user_id','item_id']].apply(LabelEncoder().fit_transform)\n",
    "df['rating']=rating['rating']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iM-mbb4Gm2w0"
   },
   "source": [
    "#### Making the dataset into surprise dataset and splitting it into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGfYDiOCpe4X"
   },
   "outputs": [],
   "source": [
    "# instantiating Reader scale with expected rating scale\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# loading the rating dataset\n",
    "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# splitting the data into train and test dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmHTEt7TnVNC"
   },
   "source": [
    "### Now we are ready to build the first baseline similary based recommendation system using cosine similarity and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO3FL7iape8A"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "algo_knn_user = KNNBasic(__________________)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo_knn_user.fit(__________)\n",
    "predictions = algo_knn_user.test(__________)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(_______________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa6OHXqE6Z1b"
   },
   "source": [
    "#### Q 3.1 What is the RMSE for baseline user based collaborative filtering recommendation system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE5kvdZenVNC"
   },
   "source": [
    "**Wite your Answer here:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gfBQGRh6Z1b"
   },
   "source": [
    "#### Q 3.2 What is the Predicted  rating for an user with userId=0 and for itemId= 3906 and itemId=100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reFD0-nsnVNC"
   },
   "source": [
    "Let's us now predict rating for an user with `userId=0` and for `itemId=3906` as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxd23bZ9pe_x"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "algo_knn_user.predict(____,____, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuVbIR3SnVNE"
   },
   "source": [
    "**Write your Answer here:________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXSgq8OEnVNE"
   },
   "source": [
    "Below we are predicting rating for the same `userId=0` but for a item which this user has not interacted before i.e. `itemId=100`, as shown below - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbFcBj1PpfEV"
   },
   "outputs": [],
   "source": [
    "algo_knn_user.predict(0,100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cm2xqtcQnVNE"
   },
   "source": [
    "**Write your Answer here:_____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejjof6csnVNF"
   },
   "source": [
    "### Improving similarity based recommendation system by tuning its hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_kxe-_JnVNF"
   },
   "source": [
    "Below we will be tuning hyper-parmeters for the `KNNBasic` algorithms. Let's try to understand different hyperparameters of KNNBasic algorithm - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2j4VvfQnVNF"
   },
   "source": [
    "- **k** (int) – The (max) number of neighbors to take into account for aggregation (see this note). Default is 40.\n",
    "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.\n",
    "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise - \n",
    "    - cosine\n",
    "    - msd (default)\n",
    "    - pearson\n",
    "    - pearson baseline\n",
    "    \n",
    "For more details please refer the official documentation https://surprise.readthedocs.io/en/stable/knn_inspired.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VSq_9J36Z1c"
   },
   "source": [
    "#### Q 3.3 Perform hyperparameter tuning for the baseline user based collaborative filtering recommendation system and find the RMSE for tuned user based collaborative filtering recommendation system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpGhU15gpfHg"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "# setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {__________}\n",
    "\n",
    "# performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(_________, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2fHNvu7nVNF"
   },
   "source": [
    "Once the grid search is complete, we can get the optimal values for each of those hyperparameters as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_K6yd6XnVNF"
   },
   "source": [
    "Below we are analysing evaluation metrics - RMSE and MAE at each and every split to analyze the impact of each value of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzJxk_Z4q1A8"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHWgxu_YnVNG"
   },
   "source": [
    "Now we will building final model by using tuned values of the hyperparameters which we received by using grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PujRJA8X_JEJ"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "# using the optimal similarity measure for user-user based collaborative filtering\n",
    "# creating an instance of KNNBasic with optimal hyperparameter values\n",
    "similarity_algo_optimized_user = KNNBasic(___________,Verbose=False)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "similarity_algo_optimized_user.fit(___________)\n",
    "\n",
    "# predicting ratings for the testset\n",
    "predictions = similarity_algo_optimized_user.test(__________)\n",
    "\n",
    "# computing RMSE on testset\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA37vQ6qnVNG"
   },
   "source": [
    "**Write your Answer here:__________**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlB0pt5F6Z1d"
   },
   "source": [
    "#### Q 3.4  What is the Predicted  rating for an user with userId=0 and for itemId= 3906 and itemId=100 using tuned user based collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhcAXK0CnVNG"
   },
   "source": [
    "Let's us now predict rating for an user with `userId=0` and for `itemId=3906` with the optimized model as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgV63lHiq1TV"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "similarity_algo_optimized_user.predict(___,___, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMBeqeUtnVNG"
   },
   "source": [
    "**Write your Answer here:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1JLqz6mnVNH"
   },
   "source": [
    "Below we are predicting rating for the same `userId=0` but for a item which this user has not interacted before i.e. `itemId=100`, by using the optimized model as shown below - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXO2Ztjhq1bN"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "similarity_algo_optimized_user.predict(__,___, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN_tYvepnVNH"
   },
   "source": [
    "**Write your Answer here:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_zwO_FnVNH"
   },
   "source": [
    "#### Identifying similar users to a given user (nearest neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2QsfqhanVNH"
   },
   "source": [
    "We can also find out the similar users to a given user or its nearest neighbors based on this KNNBasic algorithm. Below we are finding 5 most similar user to the `userId=0` based on the `msd` distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evkmTb6P5HYO"
   },
   "outputs": [],
   "source": [
    "similarity_algo_optimized_user.get_neighbors(0, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0NsrX_anVNH"
   },
   "source": [
    "#### Implementing the recommendation algorithm based on optimized KNNBasic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ESobDynVNI"
   },
   "source": [
    "Below we will be implementing a function where the input parameters are - \n",
    "\n",
    "- data: a rating dataset\n",
    "- user_id: an user id against which we want the recommendations\n",
    "- top_n: the number of items we want to recommend\n",
    "- algo: the algorithm we want to use to predict the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vW9V1Tk65HlY"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "    \n",
    "    # creating an empty list to store the recommended item ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # creating an user item interactions matrix \n",
    "    user_item_interactions_matrix = data.pivot(index='user_id', columns='item_id', values='rating')\n",
    "    \n",
    "    # extracting those item ids which the user_id has not interacted yet\n",
    "    non_interacted_items = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "    \n",
    "    # looping through each of the item id which user_id has not interacted yet\n",
    "    for item_id in non_interacted_items:\n",
    "        \n",
    "        # predicting the ratings for those non interacted item ids by this user\n",
    "        est = algo.predict(user_id, item_id).est\n",
    "        \n",
    "        # appending the predicted ratings\n",
    "        recommendations.append((item_id, est))\n",
    "\n",
    "    # sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return recommendations[:top_n] # returing top n highest predicted rating items for this user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj_S7kh4nVNI"
   },
   "source": [
    "#### Predicted top 5 items for userId=4 with similarity based recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWbR85mI5Hrk"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "recommendations = get_recommendations(df,__,___,__________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-UriRJa6Z1g"
   },
   "source": [
    "#### Q 3.5 Predict the top 5 items for userId=4 with similarity based recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5WfIX0Z6_q2"
   },
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBXXS17c6Z1g"
   },
   "source": [
    "### Model 3 Item based Collaborative Filtering Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4zF583_6Z1g"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "#definfing similarity measure\n",
    "sim_options = {__________}\n",
    "\n",
    "#defining Nearest neighbour algorithm\n",
    "algo_knn_item = KNNBasic(__________,verbose=False)\n",
    "\n",
    "# Train the algorithm on the trainset or fitting the model on train dataset \n",
    "algo_knn_item.fit(___________)\n",
    "\n",
    "#predict ratings for the testset\n",
    "predictions = algo_knn_item.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuKBx6p26Z1g"
   },
   "source": [
    "#### Q 4.1 What is the RMSE for baseline item based collaborative filtering recommendation system ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0E9OBxL46Z1g"
   },
   "source": [
    "**Write your Answer here:______**\n",
    "\n",
    "#### Let's us now predict rating for an user with `userId=0` and for `itemId=3906` and `itemId=100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmtSba906Z1h"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "algo_knn_item.predict(___, ___, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLYUottz6Z1h"
   },
   "source": [
    "As we can see - the actual rating for this user-item pair is 4 and predicted rating is 4.29 by this similarity based baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2cK6nrF6Z1h"
   },
   "source": [
    "#### Let's predict  the rating for the same `userId=0` but for a item which this user has not interacted before i.e. `itemId=22607`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GMQ0JtI6Z1h"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "algo_knn_item.predict(___,___, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC-69jMN6Z1h"
   },
   "source": [
    "As we can see the estimated rating for this user-item pair is 5.00 based on this similarity based baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EfFKfAk6Z1h"
   },
   "source": [
    "#### Q 4.3 Perform hyperparameter tuning for the baseline item based collaborative filtering recommendation system and find the RMSE for tuned item based collaborative filtering recommendation system? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu1tFaCU6Z1j"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "# setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {__________}\n",
    "\n",
    "# performing 3-fold cross validation to tune the hyperparameters\n",
    "grid_obj = GridSearchCV(________,_________, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "# fitting the data\n",
    "grid_obj.fit(_________)\n",
    "\n",
    "# best RMSE score\n",
    "print(grid_obj.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(grid_obj.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJZsNiSB6Z1j"
   },
   "source": [
    "Once the grid search is complete, we can get the optimal values for each of those hyperparameters as shown above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHXRbrsz6Z1j"
   },
   "source": [
    "Below we are analysing evaluation metrics - RMSE and MAE at each and every split to analyze the impact of each value of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjS_TXyS6Z1j"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(grid_obj.cv_results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUxmBpSj6Z1j"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "# creating an instance of KNNBasic with optimal hyperparameter values\n",
    "similarity_algo_optimized_item = KNNBasic(sim_options=________, k=__, min_k=_,verbose=False)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "similarity_algo_optimized_item.fit(___________)\n",
    "\n",
    "# predicting ratings for the testset\n",
    "predictions = similarity_algo_optimized_item.test(____________)\n",
    "\n",
    "# computing RMSE on testset\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLrYQTcz6Z1k"
   },
   "source": [
    "**Write your Answer here:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnlsOipl6Z1k"
   },
   "source": [
    "#### Q 4.4 What is the Predicted rating for an item with userId=0 and for itemId= 3906 and itemId=100 using tuned item based collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEXwA-TT6Z1k"
   },
   "source": [
    "#### Let's us now predict rating for an user with `userId=0` and for `itemId=3906` with the optimized model as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ykMV5y26Z1k"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "similarity_algo_optimized_item.predict(__,__, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPGpA30S6Z1k"
   },
   "source": [
    "**Write your Answer here:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzjpEdMN6Z1k"
   },
   "source": [
    "#### Let's predict the rating for the same `userId=0` but for a item which this user has not interacted before i.e. `itemId=100`, by using the optimized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73PUY4Og6Z1k"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "similarity_algo_optimized_item.predict(___,___, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o73veUsw6Z1k"
   },
   "source": [
    "**Write your Answer here:_______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8lUjCZA6Z1k"
   },
   "source": [
    "#### Identifying similar users to a given user (nearest neighbors)\n",
    "We can also find out the similar users to a given user or its nearest neighbors based on this KNNBasic algorithm. Below we are finding 5 most similar user to the `userId=4` based on the `msd` distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Haj3yoKO6Z1k"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "similarity_algo_optimized_item.get_neighbors(___, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txuyYKAN6Z1k"
   },
   "source": [
    "#### Predicted top 5 items for userId=4 with similarity based recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wu5p60aM6Z1k"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "recommendations = get_recommendations(df,___,___, similarity_algo_optimized_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOmy53wq6Z1l"
   },
   "source": [
    "#### Q 4.5 Predict the top 5 items for userId=4 with similarity based recommendation system ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UCb7qE96Z1l"
   },
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKgJpSA9vOOL"
   },
   "source": [
    "### Model 4 Based Collaborative Filtering - Matrix Factorization using SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF6ZGyqhCAob"
   },
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxGWVpOMvOOL"
   },
   "source": [
    "**Latent Features:** The features that are not present in the empirical data but can be inferred from the data. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4Otha8ovOOL"
   },
   "source": [
    "#### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sGl3QkLvOOL"
   },
   "source": [
    "SVD is used to compute the latent features from the user-item matrix that we already learned earlier. But SVD does not work when we missing values in the user-item matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOtkUXmAnVNL"
   },
   "source": [
    "#### Building a baseline matrix factorization recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07-2PT5Ssjqm"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "# using SVD matrix factorization\n",
    "algo_svd = SVD()\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "algo_svd.fit(_________)\n",
    "\n",
    "# predicting ratings for the testset\n",
    "predictions = algo_svd.test(___________)\n",
    "\n",
    "# computing RMSE on the testset\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG_1tO3U6Z1o"
   },
   "source": [
    "#### Q 5.1 What is the RMSE for baseline SVD based collaborative filtering recommendation system? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ6fTuCDnVNL"
   },
   "source": [
    "**Write your Answer here:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6Mv_jGn6Z1o"
   },
   "source": [
    "#### Q 5.2 What is the Predicted  rating for an user with userId =0 and for itemId= 3906 and itemId=100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD2AU1DnnVNM"
   },
   "source": [
    "Let's us now predict rating for an user with `userId=0` and for `itemId=3906` as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWIhfdxXsjqm"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "algo_svd.predict(____,____, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIjzqDY5nVNM"
   },
   "source": [
    "**Write your Answer here:_______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1aYxVeMnVNM"
   },
   "source": [
    "Below we are predicting rating for the same `userId=0` but for a item which this user has not interacted before i.e. `userId=100`, as shown below - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APm-uMSvcAMf"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "algo_svd.predict(____,___, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEL6dy3wnVNM"
   },
   "source": [
    "**Write your Answer here:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x13Eb9Owvpcw"
   },
   "source": [
    "#### Improving matrix factorization based recommendation system by tuning its hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbd3L1d2nVNM"
   },
   "source": [
    "In SVD, rating is predicted as - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wp38lmEqnVNM"
   },
   "source": [
    "$$\\hat{r}_{u i}=\\mu+b_{u}+b_{i}+q_{i}^{T} p_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHVAYuFznVNN"
   },
   "source": [
    "If user $u$ is unknown, then the bias $b_{u}$ and the factors $p_{u}$ are assumed to be zero. The same applies for item $i$ with $b_{i}$ and $q_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCfY5mr7nVNN"
   },
   "source": [
    "To estimate all the unknown, we minimize the following regularized squared error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WyyjmK7nVNN"
   },
   "source": [
    "$$\\sum_{r_{u i} \\in R_{\\text {train }}}\\left(r_{u i}-\\hat{r}_{u i}\\right)^{2}+\\lambda\\left(b_{i}^{2}+b_{u}^{2}+\\left\\|q_{i}\\right\\|^{2}+\\left\\|p_{u}\\right\\|^{2}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GBMNL9qnVNN"
   },
   "source": [
    "The minimization is performed by a very straightforward **stochastic gradient descent**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwJJRsJGnVNN"
   },
   "source": [
    "$$\\begin{aligned} b_{u} & \\leftarrow b_{u}+\\gamma\\left(e_{u i}-\\lambda b_{u}\\right) \\\\ b_{i} & \\leftarrow b_{i}+\\gamma\\left(e_{u i}-\\lambda b_{i}\\right) \\\\ p_{u} & \\leftarrow p_{u}+\\gamma\\left(e_{u i} \\cdot q_{i}-\\lambda p_{u}\\right) \\\\ q_{i} & \\leftarrow q_{i}+\\gamma\\left(e_{u i} \\cdot p_{u}-\\lambda q_{i}\\right) \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuRjcsUknVNN"
   },
   "source": [
    "There are many hyperparameters to tune in this algorithm, you can find a full list of hyperparameters [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQcDPhhcnVNN"
   },
   "source": [
    "Below we will be tuning only three hyperparameters -\n",
    "- **n_epochs**: The number of iteration of the SGD algorithm\n",
    "- **lr_all**: The learning rate for all parameters\n",
    "- **reg_all**: The regularization term for all parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTJ_9Doi6Z1r"
   },
   "source": [
    "#### Q 5.3 Perform hyperparameter tuning for the baseline SVD based collaborative filtering recommendation system and find the RMSE for tuned SVD based collaborative filtering recommendation system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bM81V_hvtwv"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "# set the parameter space to tune\n",
    "param_grid = {'n_epochs': [10, 20, 30], 'lr_all': [0.001, 0.005, 0.01],\n",
    "              'reg_all': [0.2, 0.4, 0.6]}\n",
    "\n",
    "# performing 3-fold gridsearch cross validation\n",
    "gs = GridSearchCV(_______, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting data\n",
    "gs.fit(_______)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjIaWSIAnVNN"
   },
   "source": [
    "Once the grid search is complete, we can get the optimal values for each of those hyperparameters as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CfLdGf0nVNN"
   },
   "source": [
    "Below we are analysing evaluation metrics - RMSE and MAE at each and every split to analyze the impact of each value of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMb3t3z_vt8W"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzY78HsrnVNO"
   },
   "source": [
    "Now we will building final model by using tuned values of the hyperparameters which we received by using grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TA_7xe-nnhuu"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "\n",
    "# building the optimized SVD model using optimal hyperparameter search\n",
    "svd_algo_optimized = SVD(n_epochs=20, lr_all=0.01, reg_all=0.2)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "svd_algo_optimized.fit(_______)\n",
    "\n",
    "# predicting ratings for the testset\n",
    "predictions = svd_algo_optimized.test(_________)\n",
    "\n",
    "# computing RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TYTJrFc6Z1s"
   },
   "source": [
    "#### Q 5.4 What is the Predicted rating for an user with userId=0 and for itemId= 3906 and itemId=100 using SVD based collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md0-dL56nVNO"
   },
   "source": [
    "Let's us now predict rating for an user with `userId=0` and for `itemId=3906` with the optimized model as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6C1PAfboM8_"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "svd_algo_optimized.predict(___,___, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdiEtzEznVNO"
   },
   "source": [
    "**Write your Answer here:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1xjn3kOoQyg"
   },
   "outputs": [],
   "source": [
    "#remove _______- and complete the code\n",
    "svd_algo_optimized.predict(___,___, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNy4VoXW6Z1s"
   },
   "source": [
    "#### Q 5.5 Predict the top 5 items for userId=4 with SVD based recommendation system ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LGeE2EB_n90"
   },
   "outputs": [],
   "source": [
    "get_recommendations(df,___,___, svd_algo_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgKmqss1vqGz"
   },
   "source": [
    "### Predicting ratings for already interacted items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEHotB5bhFYE"
   },
   "source": [
    "Below we are comparing the rating predictions of users for those items which has been already watched by an user. This will help us to understand how well are predictions are as compared to the actual ratings provided by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQIPHA7-vg7W"
   },
   "outputs": [],
   "source": [
    "def predict_already_interacted_ratings(data, user_id, algo):\n",
    "    \n",
    "    # creating an empty list to store the recommended item ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # creating an user item interactions matrix \n",
    "    user_item_interactions_matrix = data.pivot(index='user_id', columns='item_id', values='rating')\n",
    "    \n",
    "    # extracting those item ids which the user_id has interacted already\n",
    "    interacted_items = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].notnull()].index.tolist()\n",
    "    \n",
    "    # looping through each of the item id which user_id has interacted already\n",
    "    for item_id in interacted_items:\n",
    "        \n",
    "        # extracting actual ratings\n",
    "        actual_rating = user_item_interactions_matrix.loc[user_id, item_id]\n",
    "        \n",
    "        # predicting the ratings for those non interacted item ids by this user\n",
    "        predicted_rating = algo.predict(user_id, item_id).est\n",
    "        \n",
    "        # appending the predicted ratings\n",
    "        recommendations.append((item_id, actual_rating, predicted_rating))\n",
    "\n",
    "    # sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return pd.DataFrame(recommendations, columns=['itemId', 'actual_rating', 'predicted_rating']) # returing top n highest predicted rating items for this user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqfd_lnnhFYE"
   },
   "source": [
    "Here we are comparing the predicted ratings by `similarity based recommendation` system against actual ratings for `userId=4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWQvGj-vyWj3"
   },
   "outputs": [],
   "source": [
    "predicted_ratings_for_interacted_items = predict_already_interacted_ratings(df,4, similarity_algo_optimized)\n",
    "data = predicted_ratings_for_interacted_items.melt(id_vars='itemId', value_vars=['actual_rating', 'predicted_rating'])\n",
    "sns.displot(data=data, x='value', hue='variable', kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E6K5sFrhFYE"
   },
   "source": [
    "**Write your Answer here:**\n",
    "\n",
    "We can see that distribution of predicted ratings is closely following the distribution of actual ratings. The total bins for predicted ratings is higher as compared to total bins for actual ratings. This is expected, as actual ratings always have discreet values like 1, 2, 3, 4, 5, but predicted ratings can have continuous values as we are taking aggregated ratings from the nearest neighbors of a given user. But over the predictions looks good as compared to the distribution of actual ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD6iLaDLhFYF"
   },
   "source": [
    "Below we are comparing the predicted ratings by `matrix factorization based recommendation` system against actual ratings for `userId=4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lYjMDhU0xuQ"
   },
   "outputs": [],
   "source": [
    "predicted_ratings_for_interacted_items = predict_already_interacted_ratings(df,4, svd_algo_optimized)\n",
    "data = predicted_ratings_for_interacted_items.melt(id_vars='itemId', value_vars=['actual_rating', 'predicted_rating'])\n",
    "sns.displot(data=data, x='value', hue='variable', kde=True);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practice_Project_Product_Recommendation_Learners_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
